{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1dd2f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "import time\n",
    "# print(coffea.__version__)\n",
    "from coffea import util\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema, BaseSchema\n",
    "import mplhep as hep\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use([hep.style.CMS, hep.style.firamath])\n",
    "import hist\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "744bf209-2739-4de5-beab-aac72fb02577",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from python.plugins import runCoffeaJob\n",
    "from python.triggerProcessor import triggerProcessor, applyPrescales\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e3cc52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on LPC Condor\n",
      "[                                        ] | 0% Completed |  2min  1.6s\u001b[2K\r"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "file not found ([ERROR] Server responded with an error: [3011] Too many attempts to gain dfs read access to the file\n)\n\n    'root://cmsxrootd.hep.wisc.edu:1094//store/data/Run2016E/JetHT/NANOAOD/HIPM_UL2016_MiniAODv2_NanoAODv9-v2/40000/F21A18CF-BCA6-A943-A6C1-CB93F6F73D23.root'\n\nFiles may be specified as:\n   * str/bytes: relative or absolute filesystem path or URL, without any colons\n         other than Windows drive letter or URL schema.\n         Examples: \"rel/file.root\", \"C:\\abs\\file.root\", \"http://where/what.root\"\n   * str/bytes: same with an object-within-ROOT path, separated by a colon.\n         Example: \"rel/file.root:tdirectory/ttree\"\n   * pathlib.Path: always interpreted as a filesystem path or URL only (no\n         object-within-ROOT path), regardless of whether there are any colons.\n         Examples: Path(\"rel:/file.root\"), Path(\"/abs/path:stuff.root\")\n\nFunctions that accept many files (uproot.iterate, etc.) also allow:\n   * glob syntax in str/bytes and pathlib.Path.\n         Examples: Path(\"rel/*.root\"), \"/abs/*.root:tdirectory/ttree\"\n   * dict: keys are filesystem paths, values are objects-within-ROOT paths.\n         Example: {\"/data_v1/*.root\": \"ttree_v1\", \"/data_v2/*.root\": \"ttree_v2\"}\n   * already-open TTree objects.\n   * iterables of the above.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets_UL_NANOAOD.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# filename = \"datasets_JetHT_NOAK8PFHLT.json\"\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrunCoffeaJob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjsonFile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasa\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesting\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoffeaOutput/triggerAssignment_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(datastring, processor\u001b[38;5;241m.\u001b[39myear, processor\u001b[38;5;241m.\u001b[39mtrigger), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     14\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump( result, f)\n",
      "File \u001b[0;32m/srv/python/plugins.py:165\u001b[0m, in \u001b[0;36mrunCoffeaJob\u001b[0;34m(processor_inst, jsonFile, dask, casa, testing, year, data, winterfell, verbose)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    164\u001b[0m                     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 165\u001b[0m                     result, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mrun_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvents\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mprocessor_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessor_inst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m                     \u001b[38;5;28;01mdel\u001b[39;00m metrics\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m#         print(\"Waiting for at least one worker...\")\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/coffea/processor/executor.py:1700\u001b[0m, in \u001b[0;36mRunner.__call__\u001b[0;34m(self, fileset, treename, processor_instance)\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1680\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1681\u001b[0m     fileset: Dict,\n\u001b[1;32m   1682\u001b[0m     treename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   1683\u001b[0m     processor_instance: ProcessorABC,\n\u001b[1;32m   1684\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Accumulatable:\n\u001b[1;32m   1685\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the processor_instance on a given fileset\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \n\u001b[1;32m   1687\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m \u001b[38;5;124;03m            An instance of a class deriving from ProcessorABC\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1700\u001b[0m     wrapped_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1701\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dataframes:\n\u001b[1;32m   1702\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_out  \u001b[38;5;66;03m# not wrapped anymore\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/coffea/processor/executor.py:1782\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self, fileset, processor_instance, treename)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m fileset\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1782\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1785\u001b[0m     pi_to_send \u001b[38;5;241m=\u001b[39m processor_instance\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/coffea/processor/executor.py:1734\u001b[0m, in \u001b[0;36mRunner.preprocess\u001b[0;34m(self, fileset, treename)\u001b[0m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filemeta \u001b[38;5;129;01min\u001b[39;00m fileset:\n\u001b[1;32m   1732\u001b[0m     filemeta\u001b[38;5;241m.\u001b[39mmaybe_populate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_cache)\n\u001b[0;32m-> 1734\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preprocess_fileset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1735\u001b[0m fileset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_badfiles(fileset)\n\u001b[1;32m   1737\u001b[0m \u001b[38;5;66;03m# reverse fileset list to match the order of files as presented in version\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;66;03m# v0.7.4. This fixes tests using maxchunks.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/coffea/processor/executor.py:1461\u001b[0m, in \u001b[0;36mRunner._preprocess_fileset\u001b[0;34m(self, fileset)\u001b[0m\n\u001b[1;32m   1454\u001b[0m pre_executor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_executor\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpre_arg_override)\n\u001b[1;32m   1455\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m   1456\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautomatic_retries,\n\u001b[1;32m   1457\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries,\n\u001b[1;32m   1458\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipbadfiles,\n\u001b[1;32m   1459\u001b[0m     partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_fetcher, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxrootdtimeout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign_clusters),\n\u001b[1;32m   1460\u001b[0m )\n\u001b[0;32m-> 1461\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[43mpre_executor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_get\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m out:\n\u001b[1;32m   1463\u001b[0m     item \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mpop()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/coffea/processor/executor.py:972\u001b[0m, in \u001b[0;36mDaskExecutor.__call__\u001b[0;34m(self, items, function, accumulator)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;66;03m# FIXME: fancy widget doesn't appear, have to live with boring pbar\u001b[39;00m\n\u001b[1;32m    968\u001b[0m         progress(work, multi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, notebook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    969\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    970\u001b[0m         accumulate(\n\u001b[1;32m    971\u001b[0m             [\n\u001b[0;32m--> 972\u001b[0m                 \u001b[43mwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    973\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    974\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m _decompress(work\u001b[38;5;241m.\u001b[39mresult())\n\u001b[1;32m    975\u001b[0m             ],\n\u001b[1;32m    976\u001b[0m             accumulator,\n\u001b[1;32m    977\u001b[0m         ),\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    979\u001b[0m     )\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m KilledWorker \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    981\u001b[0m     baditem \u001b[38;5;241m=\u001b[39m key_to_item[ex\u001b[38;5;241m.\u001b[39mtask]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/distributed/client.py:287\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    286\u001b[0m     typ, exc, tb \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcancelled\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/coffea/processor/executor.py:1367\u001b[0m, in \u001b[0;36mautomatic_retries\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1362\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1363\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m skipbadfiles\n\u001b[1;32m   1364\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuth failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m chain)\n\u001b[1;32m   1365\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m retries \u001b[38;5;241m==\u001b[39m retry_count\n\u001b[1;32m   1366\u001b[0m     ):\n\u001b[0;32m-> 1367\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1368\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempt \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (retry_count \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, retries \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   1369\u001b[0m retry_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/coffea/processor/executor.py:1336\u001b[0m, in \u001b[0;36mautomatic_retries\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retry_count \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m retries:\n\u001b[1;32m   1335\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1336\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1337\u001b[0m     \u001b[38;5;66;03m# catch xrootd errors and optionally skip\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;66;03m# or retry to read the file\u001b[39;00m\n\u001b[1;32m   1339\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/coffea/processor/executor.py:1417\u001b[0m, in \u001b[0;36mmetadata_fetcher\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmetadata_fetcher\u001b[39m(\n\u001b[1;32m   1415\u001b[0m     xrootdtimeout: \u001b[38;5;28mint\u001b[39m, align_clusters: \u001b[38;5;28mbool\u001b[39m, item: FileMeta\n\u001b[1;32m   1416\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Accumulatable:\n\u001b[0;32m-> 1417\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m uproot\u001b[38;5;241m.\u001b[39mopen({item\u001b[38;5;241m.\u001b[39mfilename: \u001b[38;5;28;01mNone\u001b[39;00m}, timeout\u001b[38;5;241m=\u001b[39mxrootdtimeout) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m   1418\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1419\u001b[0m             tree \u001b[38;5;241m=\u001b[39m file[item\u001b[38;5;241m.\u001b[39mtreename]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/uproot/reading.py:141\u001b[0m, in \u001b[0;36mopen\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m uproot\u001b[38;5;241m.\u001b[39m_util\u001b[38;5;241m.\u001b[39misstr(file_path) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseek\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m ):\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a string, pathlib.Path, an object with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseek\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m methods, or a length-1 dict of \u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124mfile_path: object_path}}, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mrepr\u001b[39m(path))\n\u001b[1;32m    139\u001b[0m     )\n\u001b[0;32m--> 141\u001b[0m file \u001b[38;5;241m=\u001b[39m ReadOnlyFile(\n\u001b[1;32m    142\u001b[0m     file_path,\n\u001b[1;32m    143\u001b[0m     object_cache\u001b[38;5;241m=\u001b[39mobject_cache,\n\u001b[1;32m    144\u001b[0m     array_cache\u001b[38;5;241m=\u001b[39marray_cache,\n\u001b[1;32m    145\u001b[0m     custom_classes\u001b[38;5;241m=\u001b[39mcustom_classes,\n\u001b[1;32m    146\u001b[0m     decompression_executor\u001b[38;5;241m=\u001b[39mdecompression_executor,\n\u001b[1;32m    147\u001b[0m     interpretation_executor\u001b[38;5;241m=\u001b[39minterpretation_executor,\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions,  \u001b[38;5;66;03m# NOTE: a comma after **options breaks Python 2\u001b[39;00m\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m object_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mroot_directory\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/uproot/reading.py:580\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_before_create_source()\n\u001b[1;32m    577\u001b[0m Source, file_path \u001b[38;5;241m=\u001b[39m uproot\u001b[38;5;241m.\u001b[39m_util\u001b[38;5;241m.\u001b[39mfile_path_to_source_class(\n\u001b[1;32m    578\u001b[0m     file_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_source \u001b[38;5;241m=\u001b[39m Source(\n\u001b[1;32m    581\u001b[0m     file_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options  \u001b[38;5;66;03m# NOTE: a comma after **options breaks Python 2\u001b[39;00m\n\u001b[1;32m    582\u001b[0m )\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_before_get_chunks()\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin_chunk_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m _file_header_fields_big\u001b[38;5;241m.\u001b[39msize:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/uproot/source/xrootd.py:272\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path \u001b[38;5;241m=\u001b[39m file_path\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/uproot/source/xrootd.py:275\u001b[0m, in \u001b[0;36m_open\u001b[0;34m()\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource \u001b[38;5;241m=\u001b[39m XRootDResource(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout)\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;66;03m# this ThreadPool does not need a resource, it's only used to submit\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# futures that wait for chunks that have been split to merge them.\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor \u001b[38;5;241m=\u001b[39m uproot\u001b[38;5;241m.\u001b[39msource\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mResourceThreadPoolExecutor(\n\u001b[1;32m    280\u001b[0m         [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_workers)]\n\u001b[1;32m    281\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/uproot/source/xrootd.py:83\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path \u001b[38;5;241m=\u001b[39m file_path\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m=\u001b[39m timeout\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/uproot/source/xrootd.py:92\u001b[0m, in \u001b[0;36m_open\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m status, dummy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xrd_timeout())\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status\u001b[38;5;241m.\u001b[39merror:\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xrd_error(status)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/uproot/source/xrootd.py:115\u001b[0m, in \u001b[0;36m_xrd_error\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;66;03m# https://github.com/xrootd/xrootd/blob/8e91462e76ab969720b40fc324714b84e0b4bd42/src/XrdCl/XrdClStatus.hh#L47-L103\u001b[39;00m\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;66;03m# https://github.com/xrootd/xrootd/blob/250eced4d3787c2ac5be2c8c922134153bbf7f08/src/XrdCl/XrdClStatus.cc#L34-L74\u001b[39;00m\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m status\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m101\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m status\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m304\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m status\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[0;32m--> 115\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m uproot\u001b[38;5;241m.\u001b[39m_util\u001b[38;5;241m.\u001b[39m_file_not_found(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path, status\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m                \u001b[39m\u001b[38;5;124;03m\"\"\"XRootD error: {}\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03min file {}\"\"\"\u001b[39;00m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    121\u001b[0m                     status\u001b[38;5;241m.\u001b[39mmessage, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path\n\u001b[1;32m    122\u001b[0m                 )\n\u001b[1;32m    123\u001b[0m             )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: file not found ([ERROR] Server responded with an error: [3011] Too many attempts to gain dfs read access to the file\n)\n\n    'root://cmsxrootd.hep.wisc.edu:1094//store/data/Run2016E/JetHT/NANOAOD/HIPM_UL2016_MiniAODv2_NanoAODv9-v2/40000/F21A18CF-BCA6-A943-A6C1-CB93F6F73D23.root'\n\nFiles may be specified as:\n   * str/bytes: relative or absolute filesystem path or URL, without any colons\n         other than Windows drive letter or URL schema.\n         Examples: \"rel/file.root\", \"C:\\abs\\file.root\", \"http://where/what.root\"\n   * str/bytes: same with an object-within-ROOT path, separated by a colon.\n         Example: \"rel/file.root:tdirectory/ttree\"\n   * pathlib.Path: always interpreted as a filesystem path or URL only (no\n         object-within-ROOT path), regardless of whether there are any colons.\n         Examples: Path(\"rel:/file.root\"), Path(\"/abs/path:stuff.root\")\n\nFunctions that accept many files (uproot.iterate, etc.) also allow:\n   * glob syntax in str/bytes and pathlib.Path.\n         Examples: Path(\"rel/*.root\"), \"/abs/*.root:tdirectory/ttree\"\n   * dict: keys are filesystem paths, values are objects-within-ROOT paths.\n         Example: {\"/data_v1/*.root\": \"ttree_v1\", \"/data_v2/*.root\": \"ttree_v2\"}\n   * already-open TTree objects.\n   * iterables of the above.\n"
     ]
    }
   ],
   "source": [
    "in_year = '2016APV'\n",
    "data_bool = True\n",
    "processor = triggerProcessor(year = in_year, trigger = 'AK8PFJet', data = data_bool)\n",
    "datastring = \"JetHT\" if processor.data == True else \"QCDsim\"\n",
    "if processor.data==False and winterfell:\n",
    "    filename = \"QCD_flat.json\"\n",
    "elif processor.data==False:\n",
    "    filename = \"fileset_QCD.json\"\n",
    "else:\n",
    "    filename = \"datasets_UL_NANOAOD.json\"\n",
    "    # filename = \"datasets_JetHT_NOAK8PFHLT.json\"\n",
    "result = runCoffeaJob(processor, jsonFile = filename, casa = False, dask = True, testing = False, year = processor.year, data = processor.data)\n",
    "with open('coffeaOutput/triggerAssignment_{}_{}_{}.pkl'.format(datastring, processor.year, processor.trigger), \"wb\") as f:\n",
    "    pickle.dump( result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5d7351-5ed7-4189-b5c8-9a8ce0bcc9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_year = '2016'\n",
    "data_bool = True\n",
    "processor = triggerProcessor(year = in_year, trigger = 'AK8PFJet', data = data_bool)\n",
    "datastring = \"JetHT\" if processor.data == True else \"QCDsim\"\n",
    "if processor.data==False and winterfell:\n",
    "    filename = \"QCD_flat.json\"\n",
    "elif processor.data==False:\n",
    "    filename = \"fileset_QCD.json\"\n",
    "else:\n",
    "    filename = \"datasets_UL_NANOAOD.json\"\n",
    "    # filename = \"datasets_JetHT_NOAK8PFHLT.json\"\n",
    "result = runCoffeaJob(processor, jsonFile = filename, casa = False, dask = True, testing = False, year = processor.year, data = processor.data)\n",
    "with open('coffeaOutput/triggerAssignment_{}_{}_{}.pkl'.format(datastring, processor.year, processor.trigger), \"wb\") as f:\n",
    "    pickle.dump( result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ea1f28-2f50-448f-9a71-7d0d8c51b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_year = '2017'\n",
    "data_bool = True\n",
    "processor = triggerProcessor(year = in_year, trigger = 'AK8PFJet', data = data_bool)\n",
    "datastring = \"JetHT\" if processor.data == True else \"QCDsim\"\n",
    "if processor.data==False and winterfell:\n",
    "    filename = \"QCD_flat.json\"\n",
    "elif processor.data==False:\n",
    "    filename = \"fileset_QCD.json\"\n",
    "else:\n",
    "    filename = \"datasets_UL_NANOAOD.json\"\n",
    "    # filename = \"datasets_JetHT_NOAK8PFHLT.json\"\n",
    "result = runCoffeaJob(processor, jsonFile = filename, casa = False, dask = True, testing = False, year = processor.year, data = processor.data)\n",
    "with open('coffeaOutput/triggerAssignment_{}_{}_{}.pkl'.format(datastring, processor.year, processor.trigger), \"wb\") as f:\n",
    "    pickle.dump( result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958a124f-ed75-4552-8b23-3bee48d5a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_year = '2018'\n",
    "data_bool = True\n",
    "processor = triggerProcessor(year = in_year, trigger = 'AK8PFJet', data = data_bool)\n",
    "datastring = \"JetHT\" if processor.data == True else \"QCDsim\"\n",
    "if processor.data==False and winterfell:\n",
    "    filename = \"QCD_flat.json\"\n",
    "elif processor.data==False:\n",
    "    filename = \"fileset_QCD.json\"\n",
    "else:\n",
    "    filename = \"datasets_UL_NANOAOD.json\"\n",
    "    # filename = \"datasets_JetHT_NOAK8PFHLT.json\"\n",
    "result = runCoffeaJob(processor, jsonFile = filename, casa = False, dask = True, testing = False, year = processor.year, data = processor.data)\n",
    "with open('coffeaOutput/triggerAssignment_{}_{}_{}.pkl'.format(datastring, processor.year, processor.trigger), \"wb\") as f:\n",
    "    pickle.dump( result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa25869-cd00-48da-b5a0-7a00fed6ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize, curve_fit\n",
    "from scipy.stats import rv_continuous, norm\n",
    "from scipy.special import erf, erfinv\n",
    "\n",
    "def fit_function(x, b, c):\n",
    "    # y = a+0.5*(1-a)*(1+erf((x-b)/c))\n",
    "    y = 0.5*(1+erf((x-b)/(np.sqrt(2)*c)))\n",
    "    return y\n",
    "#### define custom error function using scipy.stats rv_continuous --> will automatically inherit MLE fit\n",
    "\n",
    "class cust_erf(rv_continuous):\n",
    "    def _pdf(self, x, b, c):\n",
    "        # return a+0.5*(1-a)*(1+erf((x-b)/c))\n",
    "        return 0.5*(1+erf((x-b)/(np.sqrt(2)*c)))\n",
    "    #### use rv_continuous scale and loc to compute x->(x-loc)/scale\n",
    "fit_func = cust_erf(name='erf')\n",
    "print(\"rv_cont fit function: \", fit_func)\n",
    "\n",
    "#### params are b,c\n",
    "                      \n",
    "                      \n",
    "def fit_trigEff(x, data):\n",
    "    #x is the pt bin centers; data is the efficiency values\n",
    "    x0 = [np.min(x), np.min(x)]\n",
    "    popt, pcov = curve_fit(fit_function, x, data, p0 = x0)\n",
    "    # b, c, loc, scale = fit_func.fit(data, *popt, floc = 0., fscale = 1.0)\n",
    "    print(\"Basic fit results: \", popt)\n",
    "    return popt\n",
    "\n",
    "from python.plugins import checkdir\n",
    "def plot_turnOn(result, HLT):\n",
    "    hist_trigEff = result['hist_trigEff_ptCut']\n",
    "    hist_trigRef = result['hist_trigRef']\n",
    "    hist_pt = result['hist_pt']\n",
    "    HLT_paths = [path for path in list(hist_trigEff.project(\"HLT_cat\").axes[0])]\n",
    "    dataset = hist_trigEff[{\"HLT_cat\":slice(0,hist.overflow-1,sum)}].axes[0][0]\n",
    "    os_path = 'plots/triggerStudies'+ dataset+'/'\n",
    "    checkdir(os_path)\n",
    "    print('HLT_paths:', HLT_paths)\n",
    "    trigThresh = [int(path.replace(HLT, '')) for path in HLT_paths]\n",
    "    turnOnPts = {}\n",
    "    turnOnPts_ptCut = {}\n",
    "    for i in np.arange(len(HLT_paths)):\n",
    "        path = HLT_paths[i]\n",
    "        print(\"Path = \", path)\n",
    "        print(\"dataset: \", dataset)\n",
    "        # print(\"trigeffvalues for path: \", hist_trigEff[{\"HLT_cat\":path}])\n",
    "        #### numerator is number of events that belong to trigger path below and have pt > current trigger thresh\n",
    "        numerator = hist_trigEff[{\"HLT_cat\":path}].values()[0]\n",
    "        #### denominator is number of events in trigger below\n",
    "        denominator = hist_trigRef[{\"HLT_cat\":path}].values()[0]\n",
    "        num = numerator[denominator > 0]\n",
    "        denom = denominator[denominator > 0]\n",
    "        efficiency = num / denom\n",
    "        # eff_hist = np.where(denominator > 0, numerator/denominator, 0)\n",
    "        eff_hist = np.divide(\n",
    "                hist_trigEff[{\"HLT_cat\":path}].values(),\n",
    "                hist_trigRef[{\"HLT_cat\":path}].values(),\n",
    "                out=np.empty(np.array(hist_trigRef[{\"HLT_cat\":path}].values()).shape).fill(np.nan),\n",
    "                where=hist_trigRef[{\"HLT_cat\":path}].values()!= 0)[0]\n",
    "        eff_hist_err = np.array([np.divide(\n",
    "                np.ones_like(hist_trigEff[{\"HLT_cat\":path}].values()),\n",
    "                np.sqrt(hist_trigRef[{\"HLT_cat\":path}].values()),\n",
    "                out=np.empty(np.array(hist_trigRef[{\"HLT_cat\":path}].values()).shape).fill(np.nan),\n",
    "                where=hist_trigRef[{\"HLT_cat\":path}].values()!= 0)[0], np.zeros_like(hist_trigRef[{\"HLT_cat\":path}].values())[0]])\n",
    "        pt_centers = hist_trigEff.axes['pt'].centers[denominator > 0]\n",
    "        # print(\"Pt centers: \", pt_centers)\n",
    "        # print(\"Pt edges: \",  hist_trigEff.axes['pt'].edges)\n",
    "        #### plot original numerator and denominator histograms\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        hist_trigEff[{\"HLT_cat\":path}].plot1d(ax=ax)\n",
    "        hist_trigRef[{\"HLT_cat\":path}].plot1d(ax=ax)\n",
    "        ax.set_title(\"Events in HLT \" + HLT_paths[i-1])\n",
    "        ax.set_xlabel(\"Leading Jet pT (GeV)\")\n",
    "        ax.set_ylim(1, None)\n",
    "        ax.legend([\"Numerator\", \"Numerator_ptCut\", \"Denominator\"])\n",
    "        plt.savefig(os_path + 'numDenom_HLT_' + path + \".png\")\n",
    "        #### Make custom fit function for the efficiencies\n",
    "        if len(efficiency) > 0:\n",
    "            fig, ax = plt.subplots(1, 1)\n",
    "            ax.set_ylim([-0.01, 1.1])\n",
    "            ### only fit points after trigger threshold\n",
    "            eff_turnon_id = np.min(np.argwhere(trigThresh[i] <= pt_centers))\n",
    "            xdata = pt_centers[eff_turnon_id+3:]\n",
    "            # print(\"pt start: \", pt_centers[eff_turnon_id])\n",
    "            ydata = efficiency[eff_turnon_id+3:]\n",
    "            popt = fit_trigEff(xdata, ydata)\n",
    "            # b_mle, c_mle, popt = fit_trigEff(pt_centers, efficiency)\n",
    "            xpts = np.linspace(pt_centers[eff_turnon_id], 2400, int((2400-pt_centers[eff_turnon_id])))\n",
    "            ### turn on point is pt value when efficiency reaches 0.99 --> solve fitted equation\n",
    "            b, c = popt\n",
    "            xdata = pt_centers[eff_turnon_id:]\n",
    "            ydata = efficiency[eff_turnon_id:]\n",
    "            def NLL(params):\n",
    "                b = params[0]\n",
    "                c = params[1]\n",
    "                y = 0.5*(1+erf((xdata-b)/(np.sqrt(2)*c)))\n",
    "                return -1*norm(y, params[2]).logpdf(ydata).sum()\n",
    "            res = minimize(NLL, [popt[0], popt[1], 1])\n",
    "            # res = minimize(NLL, [np.min(xdata), np.min(xdata), 1])\n",
    "            b_mle, c_mle, s_mle = res.x\n",
    "            print(\"MLE results \", res.x)\n",
    "            to_pt = (np.sqrt(2)*c*erfinv(2*0.99-1)) + b\n",
    "            to_pt_mle = (np.sqrt(2)*c_mle*erfinv(2*0.99-1)) + b_mle\n",
    "            turnOnPts[path] = [to_pt, to_pt_mle]\n",
    "            hep.histplot(eff_hist, hist_trigEff.axes['pt'].edges, ax = ax, label='HLT_'+path, yerr=eff_hist_err, histtype='errorbar', color = 'black', marker =[\"o\"], markersize=6,)\n",
    "            ax.plot(xpts, fit_function(xpts, *popt), label = \"Fit; to_pt = %.f\"%to_pt, color='red')\n",
    "            # ax.plot(xpts, fit_function(xpts, b_mle, c_mle), label = \"MLE fit; to_pt = %.f\"%to_pt_mle)\n",
    "            ax.set_xlabel(\"Leading Jet pT (GeV)\")\n",
    "            ax.legend()\n",
    "            plt.savefig(os_path + 'efficiency_HLT_'+path + \".png\")\n",
    "    #### plot total leading jet pt for reference\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "#     hist_pt.plot1d(ax=ax)\n",
    "    pt_hist = hist_trigEff[{\"dataset\":sum}]\n",
    "    pt_hist.plot1d(ax=ax, overlay=\"HLT_cat\", stack = True)\n",
    "    ax.set_title(\"All events\")\n",
    "    ax.set_xlabel(\"Leading Jet pT (GeV)\")\n",
    "    ax.set_ylim(1, None)\n",
    "    ax.set_xlim([180., 3200.])\n",
    "    plt.legend()\n",
    "    plt.savefig(os_path + 'HLT_' + path + \".png\")\n",
    "    \n",
    "    return turnOnPts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f2844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLT = 'PFJet'\n",
    "with open(\"coffeaOutput/triggerAssignment_JetHT_2016APV_PFJettest.pkl\", \"rb\") as f:\n",
    "    result = pickle.load( f )\n",
    "turnOnPts = plot_turnOn(result, HLT)\n",
    "print(turnOnPts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106a1229-5587-45b1-bf9d-8d2a2ec5d2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLT = 'AK8PFJet'\n",
    "with open(\"coffeaOutput/triggerAssignment_QCDsim_2017_AK8PFJet_NewHist.pkl\", \"rb\") as f:\n",
    "    result = pickle.load( f )\n",
    "turnOnPts = plot_turnOn(result, HLT)\n",
    "print(turnOnPts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db887aa-066f-468b-afcf-8cbd8df56121",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLT = 'AK8PFJet'\n",
    "result = util.load('coffeaOutput/triggerAssignment_QCDsim_2017_AK8PFJet_NewHist.coffea')\n",
    "turnOnPts = plot_turnOn(result, HLT)\n",
    "print(turnOnPts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a94f0c4-0339-4d22-b7fa-1448444b82ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "JetHT2016APV_ver2 = {'PFJet40': 0.,\n",
    "                     'PFJet60': 0., \n",
    "                     'PFJet80': 0., \n",
    "                     'PFJet140': 270., \n",
    "                     'PFJet200': 360., \n",
    "                     'PFJet260': 420.,\n",
    "                     'PFJet320': 500., \n",
    "                     'PFJet400': 620., \n",
    "                     'PFJet450': 680., \n",
    "                     'PFJet500': 750.}\n",
    "\n",
    "newnew2016APV = {'AK8PFJet60': [-907.8640999961028, 262.4735999003504], 'AK8PFJet80': [-813.8186499329943, 262.77245946851093], \n",
    " 'AK8PFJet140': [253.94444973912857, 263.3026984698921], 'AK8PFJet200': [360.0764064058382, 299.2854716580488], \n",
    "      'AK8PFJet260': [483.00287488418155, 404.4448541480781], 'AK8PFJet320': [516.4663396055998, 474.8250139929101], \n",
    "      'AK8PFJet400': [633.6486082346614, 615.3673978541681], 'AK8PFJet450': [696.4518929273487, 685.7016389352334], \n",
    "      'AK8PFJet500': [747.6266419662311, 756.0433505701444]}\n",
    "newnew2016 = {'AK8PFJet60': [-946.2357202500248, 261.7098144410188], 'AK8PFJet80': [-803.2295016490575, 262.5218607414522],\n",
    "              'AK8PFJet140': [-858.7030992093493, 263.265890230311], 'AK8PFJet200': [413.00735585819587, 299.410005622084], \n",
    "              'AK8PFJet260': [459.14663820030887, 404.4577393342188], 'AK8PFJet320': [515.2366802858614, 474.8650088075158], \n",
    "              'AK8PFJet400': [637.7194912921713, 615.3824932019286], 'AK8PFJet450': [692.9761938054255, 685.7182502373848], \n",
    "              'AK8PFJet500': [747.2057802913281, 756.0628352446492]}\n",
    "newnew2017 = {'AK8PFJet80': [-888.8257856276085, 262.90302280290547], 'AK8PFJet140': [268.4972055097363, 263.4973288928351], \n",
    "              'AK8PFJet200': [361.8933122586835, 299.2525901052801], 'AK8PFJet260': [446.46778027594905, 404.51157859921364], \n",
    "              'AK8PFJet320': [514.0152556774021, 474.94177990800785], 'AK8PFJet400': [633.369090255502, 615.465068235013], \n",
    "              'AK8PFJet450': [685.9223126308343, 685.7690678042886], 'AK8PFJet500': [743.9267302139867, 756.1055054574387], \n",
    "              'AK8PFJet550': [795.7010491595948, 826.4498999990128], 'AK8PFJet60': [-833.5216610826582, 262.3418152112348]}\n",
    "newnew2018 = {'AK8PFJet60': [-811.0145179581602, 263.0901583141537], 'AK8PFJet80': [-827.6171539282988, 263.2594121656277], \n",
    "              'AK8PFJet140': [281.81975103728195, 263.58429273913055], 'AK8PFJet200': [367.6531123322325, 299.12181095332636], \n",
    "              'AK8PFJet260': [458.9796186587356, 404.5000154037815], 'AK8PFJet320': [523.0660904166687, 474.87960485319854], \n",
    "              'AK8PFJet400': [638.7502963687823, 615.4428384628924], 'AK8PFJet450': [689.7766784490543, 685.770116976563], \n",
    "              'AK8PFJet500': [745.1851326682686, 756.1016601517806], 'AK8PFJet550': [796.7749788024962, 826.4330586079827]}\n",
    "JetHT2016_new = {'AK8PFJet40':0.,\n",
    "                 'AK8PFJet60': 0., \n",
    "                 'AK8PFJet80': 0., \n",
    "                 'AK8PFJet140': 260., \n",
    "                 'AK8PFJet200': 360., \n",
    "                 'AK8PFJet260': 450., \n",
    "                 'AK8PFJet320': 500., \n",
    "                 'AK8PFJet400': 630., \n",
    "                 'AK8PFJet450': 690., \n",
    "                 'AK8PFJet500': 750.}\n",
    "JetHT2016APV_new = {'AK8PFJet40':0., \n",
    "                     'AK8PFJet60': 0, \n",
    "                     'AK8PFJet80': 0, \n",
    "                     'AK8PFJet140': 260., \n",
    "                     'AK8PFJet200': 360., \n",
    "                     'AK8PFJet260': 450., \n",
    "                     'AK8PFJet320': 500., \n",
    "                     'AK8PFJet400': 630., \n",
    "                     'AK8PFJet450': 690., \n",
    "                     'AK8PFJet500': 750.}\n",
    "JetHT2017_new = {'AK8PFJet40':0.,\n",
    "                 'AK8PFJet60': 0., \n",
    "                 'AK8PFJet80': 0., \n",
    "                 'AK8PFJet140': 265., \n",
    "                 'AK8PFJet200': 360., \n",
    "                 'AK8PFJet260': 440., \n",
    "                 'AK8PFJet320': 500., \n",
    "                 'AK8PFJet400': 630., \n",
    "                 'AK8PFJet450': 685., \n",
    "                 'AK8PFJet500': 750., \n",
    "                 'AK8PFJet550': 800.}\n",
    "JetHT2018_new = {'AK8PFJet15': 0.,\n",
    "                 'AK8PFJet25': 0.,\n",
    "                 'AK8PFJet40': 0.,\n",
    "                 'AK8PFJet60': 0.,\n",
    "                 'AK8PFJet80': 0., \n",
    "                 'AK8PFJet140': 265., \n",
    "                 'AK8PFJet200': 360., \n",
    "                 'AK8PFJet260': 450., \n",
    "                 'AK8PFJet320': 500., \n",
    "                 'AK8PFJet400': 630., \n",
    "                 'AK8PFJet450': 685., \n",
    "                 'AK8PFJet500': 750., \n",
    "                 'AK8PFJet550': 800.}\n",
    "\n",
    "\n",
    "\n",
    "turnOnPts_2016_QCDflat = {'AK8PFJet40':0.,\n",
    "                          'AK8PFJet60': 106.79400044725446, \n",
    "                          'AK8PFJet80': 169.96352855878737, \n",
    "                          'AK8PFJet140': 265.2873364497926, \n",
    "                          'AK8PFJet200': 315.1712855987987, \n",
    "                          'AK8PFJet260': 385.9414264230047, \n",
    "                          'AK8PFJet320': 456.1785495557566, \n",
    "                          'AK8PFJet400': 528.4054384945691, \n",
    "                          'AK8PFJet450': 599.9567915817205, \n",
    "                          'AK8PFJet500': 671.8599581978826}\n",
    "\n",
    "turnOnPts_2017_QCD_flat = {'AK8PFJet40':0.,\n",
    "                           'AK8PFJet60': 78.72682467365811, \n",
    "                           'AK8PFJet80': 114.26008394028244, \n",
    "                           'AK8PFJet140': 262.69051582382326, \n",
    "                           'AK8PFJet200': 315.5082701033607, \n",
    "                           'AK8PFJet260': 391.2706193753585, \n",
    "                           'AK8PFJet320': 461.86703035451836, \n",
    "                           'AK8PFJet400': 545.2806371181599, \n",
    "                           'AK8PFJet450': 611.8168127002015, \n",
    "                           'AK8PFJet500': 681.8828608405956, \n",
    "                           'AK8PFJet550': 725.799090910656}\n",
    "\n",
    "turnOnPts_2018_QCDflat = {'AK8PFJet15': 0.,\n",
    "                          'AK8PFJet25': 0.,\n",
    "                          'AK8PFJet40': 0.,\n",
    "                          'AK8PFJet60': 0.,\n",
    "                          'AK8PFJet80': 0.,\n",
    "                          'AK8PFJet140': 255.02381002773194, \n",
    "                          'AK8PFJet200': 313.2026733979357, \n",
    "                          'AK8PFJet260': 388.2175317071178, \n",
    "                          'AK8PFJet320': 459.1304096129003, \n",
    "                          'AK8PFJet400': 530.7709332894112, \n",
    "                          'AK8PFJet450': 599.485074238053, \n",
    "                          'AK8PFJet500': 669.532328119605, \n",
    "                          'AK8PFJet550': 706.4936306567531}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7262b52d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# in_year = '2016'\n",
    "# data_bool = True\n",
    "# winterfell = False\n",
    "# processor = applyPrescales(year = in_year, trigger = 'AK8PFJet', turnOnPts = np.array(list(JetHT2016APV_new.values())), data = data_bool)\n",
    "# datastring = \"JetHT\" if processor.data == True else \"QCDsim\"\n",
    "# if processor.data==False and winterfell:\n",
    "#     filename = \"QCD_flat_files.json\"\n",
    "# elif processor.data==False:\n",
    "#     filename = \"fileset_QCD.json\"\n",
    "# else:\n",
    "#     filename = \"datasets_UL_NANOAOD.json\"\n",
    "# result = runCoffeaJob(processor, jsonFile = filename, dask=True, testing = False , year = processor.year, data = processor.data)\n",
    "# with open('coffeaOutput/applyPrescales_{}_{}_{}.pkl'.format(datastring, processor.year, processor.trigger), \"wb\") as f:\n",
    "#     pickle.dump( result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c58973-b67b-42de-b9f0-67fd3af80421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_year = '2016APV'\n",
    "# data_bool = True\n",
    "# winterfell = True\n",
    "# processor = applyPrescales(year = in_year, trigger = 'PFJet', turnOnPts = np.array(list(JetHT2016APV_ver2.values())), data = data_bool)\n",
    "# datastring = \"JetHT\" if processor.data == True else \"QCDsim\"\n",
    "# if processor.data==False and winterfell:\n",
    "#     filename = \"QCD_flat_files.json\"\n",
    "# elif processor.data==False:\n",
    "#     filename = \"fileset_QCD.json\"\n",
    "# else:\n",
    "#     filename = \"datasets_JetHT_NOAK8PFHLT.json\"\n",
    "# result = runCoffeaJob(processor, jsonFile = filename, dask=True, testing = False, year = processor.year, data = processor.data)\n",
    "# with open('coffeaOutput/applyPrescales_{}_{}_{}.pkl'.format(datastring, processor.year, processor.trigger), \"wb\") as f:\n",
    "#     pickle.dump( result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717d6825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPrescales(result, year):\n",
    "    hist_pt = result['hist_pt'][{'dataset':sum}]\n",
    "    hist_pt_byHLTpath = result['hist_pt_byHLTpath'][{'dataset':sum}]\n",
    "    plt.rcParams['figure.facecolor']='white'\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    fig, axs = plt.subplots(1, 2)      \n",
    "    print(hist_pt)\n",
    "\n",
    "    hist_pt.plot(ax = axs[0], overlay='HLT_cat')\n",
    "    axs[0].set_yscale('log')\n",
    "    axs[0].set_ylim([0.0, 1.0e10])\n",
    "    axs[0].set_title('Events sorted by HLT w/ prescale applied')\n",
    "\n",
    "    hist_pt_byHLTpath.plot(ax = axs[1], overlay='HLT_cat', stack=False, histtype='errorbar')\n",
    "    axs[1].set_yscale('log')\n",
    "    axs[1].set_ylim([0.0, 1.0e10])\n",
    "    axs[1].set_title('Doubles removed w/ prescale applied')\n",
    "\n",
    "    fig.suptitle('Apply Prescales ' + str(year), fontsize=\"large\")\n",
    "\n",
    "    plt.rc('legend',fontsize='small')\n",
    "    plt.legend()\n",
    "    dataset = 'JetHT' + str(year)\n",
    "    os_path = 'plots/triggerStudies'+ dataset + '/'\n",
    "    checkdir(os_path)\n",
    "    plt.savefig(os_path + 'applyPrescales' + str(year) + \".png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199f4acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"coffeaOutput/applyPrescales_JetHT_2016APV_PFJet.pkl\", \"rb\") as f:\n",
    "    result = pickle.load( f )\n",
    "# print(result['hist_pt'][{'HLT_cat':sum, 'pt':sum}].values())\n",
    "plotPrescales(result, '2016APV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4967ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"coffeaOutput/applyPrescales_JetHT_2016_AK8PFJet_NewHist.pkl\", \"rb\") as f:\n",
    "#     result = pickle.load( f )\n",
    "# print(result['hist_pt'][{'HLT_cat':sum, 'pt':sum}].values())\n",
    "# plotPrescales(result, '2016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc29de5-d25d-43f8-a443-7603697b7818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"coffeaOutput/applyPrescales_JetHT_2017_AK8PFJet_NewHist.pkl\", \"rb\") as f:\n",
    "#     result = pickle.load( f )\n",
    "# # print(result['hist_pt'][{'HLT_cat':sum, 'pt':sum}].values())\n",
    "# plotPrescales(result, '2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caa83d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"coffeaOutput/applyPrescales_JetHT_2016APV_AK8PFJet.pkl\", \"rb\") as f:\n",
    "    result = pickle.load( f )\n",
    "# print(result['hist_pt'][{'HLT_cat':sum, 'pt':sum}].values())\n",
    "plotPrescales(result, '2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe640b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2c76e6-7328-4dd3-b22e-56ebe553861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff6376a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
